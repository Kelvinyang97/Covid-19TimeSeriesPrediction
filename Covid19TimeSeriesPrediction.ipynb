{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19TimeSeriesPrediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNbmWQDyhYis"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMa5J6jEhite"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX4oYlN2hq64"
      },
      "source": [
        "oxford = pd.read_csv(\"/content/drive/My Drive/CHANGE_THIS_TO_YOUR_DATASET_LOCATION/Oxford Covid-19 Government Response Tracker/OxCGRT_latest.csv\")\n",
        "# political data\n",
        "pol = pd.read_csv(\"/content/drive/My Drive/CHANGE_THIS_TO_YOUR_DATASET_LOCATION/political2.csv\", encoding='latin-1')\n",
        "# cultural data\n",
        "cul = pd.read_csv(\"/content/drive/My Drive/CHANGE_THIS_TO_YOUR_DATASET_LOCATION/Hofstede national culture dimensions (2015)/6-dimensions-for-website-2015-08-16.csv\", sep = \";\")\n",
        "# health data\n",
        "health = pd.read_csv(\"/content/drive/My Drive/CHANGE_THIS_TO_YOUR_DATASET_LOCATION/World development indicators - health systems/2.12_Health_systems.csv\")\n",
        "def convertDateV2(str):\n",
        "    return datetime.strftime(datetime.strptime(str, \"%Y%m%d\"),\"%Y-%m-%d\")\n",
        "oxford[\"Date\"] = oxford[\"Date\"].astype(\"str\").apply(convertDateV2).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhQl77IljS6c"
      },
      "source": [
        "l = [\"VoiceAndAccountability\", \"PoliticalStabilityNoViolence\", \"GovernmentEffectiveness\", \"RegulatoryQuality\", \"RuleofLaw\", \"ControlofCorruption\"]\n",
        "from operator import add\n",
        "pol.columns = [\"Country\", \"Code\"]+list( map(add, np.repeat(l,6),pol.drop([\"Country\", \"Code\"], axis = 1).columns.values) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnhDDyXYkKMW"
      },
      "source": [
        "cul.at[103,\"country\"] = \"United States\"\n",
        "cul.at[83,\"country\"] = \"Russian Federation\"\n",
        "cul.at[45,\"country\"] = \"hong kong sar, china\"\n",
        "cul.at[50,\"country\"] = \"iran, islamic rep.\"\n",
        "cul.at[42,\"country\"] = \"united kingdom\"\n",
        "cul.at[107,\"country\"] = \"venezuela, rb\"\n",
        "cul_health = pd.merge(cul,health,how = \"inner\", left_on = \"country\", right_on = \"Country_Region\")\n",
        "df = pd.merge(oxford,pol,how = \"left\",left_on = \"CountryCode\", right_on = \"Code\").drop(\"Code\", axis = 1)\n",
        "##### Merges\n",
        "\n",
        "def count(x,y, string):\n",
        "    if string == \"common\":\n",
        "        return len(np.intersect1d(x.unique(),y.unique()))\n",
        "    elif string == \"diff\":\n",
        "        print(np.setxor1d(x.unique(),y.unique()))\n",
        "        return len(np.setxor1d(x.unique(),y.unique()))\n",
        "    elif string == \"leftdif\":\n",
        "        print(np.setdiff1d(y.unique(),x.unique()))\n",
        "        return len(np.setdiff1d(y.unique(),x.unique()))\n",
        "df = pd.merge(df,cul_health,how = \"left\",left_on = \"CountryName\", right_on = \"country\")\n",
        "\n",
        "!pip install pycountry\n",
        "import pycountry\n",
        "# gmr['country_region_code'].values\n",
        "def countrycodeconv(str):\n",
        "    try:\n",
        "        return pycountry.countries.get(alpha_2=str).alpha_3\n",
        "    except:\n",
        "        pass\n",
        "gmr = gmr.groupby(by = [\"country_region_code\",\"date\"]).median().reset_index()\n",
        "gmr['a3country_code'] = gmr[\"country_region_code\"].apply(countrycodeconv)\n",
        "df= pd.merge(df,gmr, how = \"left\", left_on = [\"CountryCode\",\"Date\"],right_on = [\"a3country_code\",\"date\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydHO35PoqvHM"
      },
      "source": [
        "all = pd.read_csv(\"/content/drive/My Drive/AtlassianDataSci/COMBINEDWITHPOP.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvMbMvINqy-2"
      },
      "source": [
        "actions_adopted = all[['C1_School closing','C2_Workplace closing','C3_Cancel public events','C4_Restrictions on gatherings','C5_Close public transport','C6_Stay at home requirements','C7_Restrictions on internal movement','C8_International travel controls','E1_Income support','E2_Debt/contract relief','E3_Fiscal measures','E4_International support','H1_Public information campaigns','H2_Testing policy','H3_Contact tracing','H4_Emergency investment in healthcare','H5_Investment in vaccines']]\n",
        "scopes_of_actions = all[['C1_Flag','C2_Flag','C3_Flag','C4_Flag','C5_Flag','C6_Flag','C7_Flag','E1_Flag','H1_Flag',]]\n",
        "characteristics = all[['StringencyIndex','GovernmentResponseIndex','ContainmentHealthIndex','EconomicSupportIndex']]\n",
        "governance_indicators = all[['VoiceAndAccountabilityEstimate','PoliticalStabilityNoViolenceEstimate.1','GovernmentEffectivenessEstimate.2','RegulatoryQualityEstimate.3','RuleofLawEstimate.4','ControlofCorruptionEstimate.5']]\n",
        "cultural_indicators = all[['pdi','idv','mas','ltowvs','ivr','uai']]\n",
        "country_identifier = all[['CountryName','CountryCode']]\n",
        "population_related = all[['Population (2020)','Density (P/Km²)']]\n",
        "density_related = all[['Density (P/Km²)']]\n",
        "# relevant_features = all[['Date','CountryCode','retail_and_recreation_percent_change_from_baseline','grocery_and_pharmacy_percent_change_from_baseline','parks_percent_change_from_baseline','transit_stations_percent_change_from_baseline','workplaces_percent_change_from_baseline','residential_percent_change_from_baseline','pdi','idv','mas','uai','ltowvs','ivr','Health_exp_pct_GDP_2016','Health_exp_public_pct_2016','Health_exp_out_of_pocket_pct_2016','Health_exp_per_capita_USD_2016','per_capita_exp_PPP_2016','External_health_exp_pct_2016','VoiceAndAccountabilityEstimate','PoliticalStabilityNoViolenceEstimate.1','GovernmentEffectivenessEstimate.2','RegulatoryQualityEstimate.3','RuleofLawEstimate.4','ControlofCorruptionEstimate.5']]\n",
        "date = all[['Date']]\n",
        "dep_var = all['ConfirmedCases'].divide(all['Density (P/Km²)'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e24SJ5fxq1YN"
      },
      "source": [
        "dataset = pd.concat([country_identifier,date,actions_adopted,characteristics,governance_indicators, density_related,dep_var], axis=1)\n",
        "dataset = dataset.rename(columns={0:'CasesPerPerson'}).iloc[:-1,:]\n",
        "dataset['CasesPerPerson'] = dataset['CasesPerPerson'].fillna(0)\n",
        "dataset['CasesPerPersonInInterval'] = dataset.groupby('CountryName')['CasesPerPerson'].diff()\n",
        "dataset['CasesPerPersonInInterval'] = dataset['CasesPerPersonInInterval'].fillna(0)\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'],format='%Y-%m-%d')\n",
        "valid_date = '2020-09-28'\n",
        "dataset = dataset.loc[dataset['Date'] <= valid_date]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s19bazyLrR-q"
      },
      "source": [
        "peru = dataset[dataset['CountryName'] == 'Peru']\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Use seaborn style defaults and set the default figure size\n",
        "sns.set(rc={'figure.figsize':(11, 4)})\n",
        "peru['CasesPerPersonInInterval'].plot(linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "letltAfNs81F"
      },
      "source": [
        "def create_features(df, label=None):\n",
        "    \"\"\"\n",
        "    Creates time series features from datetime index\n",
        "    \"\"\"\n",
        "    df['hour'] = df['Date'].dt.hour\n",
        "    df['dayofweek'] = df['Date'].dt.dayofweek\n",
        "    df['quarter'] = df['Date'].dt.quarter\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['year'] = df['Date'].dt.year\n",
        "    df['dayofyear'] = df['Date'].dt.dayofyear\n",
        "    df['dayofmonth'] = df['Date'].dt.day\n",
        "    df['weekofyear'] = df['Date'].dt.weekofyear\n",
        "    X = df[['hour','dayofweek','quarter','month','year',\n",
        "           'dayofyear','dayofmonth','weekofyear']]\n",
        "    if label:\n",
        "        y = df[label]\n",
        "        return X, y\n",
        "    return X\n",
        "split_date = '2020-08-01'\n",
        "peru['Date']\n",
        "peru['Date'] <= split_date\n",
        "peru_train = peru.loc[peru['Date'] <= split_date].copy()\n",
        "peru_test = peru.loc[peru['Date'] > split_date].copy()\n",
        "peru_X_train, peru_y_train = create_features(peru_train, label='CasesPerPersonInInterval')\n",
        "peru_X_test, peru_y_test = create_features(peru_test, label='CasesPerPersonInInterval')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fwEXYBfwsjp"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "plt.style.use('fivethirtyeight')\n",
        "from matplotlib import pyplot\n",
        "rf_exp = RandomForestRegressor(n_estimators= 1000)\n",
        "rf_exp.fit(peru_X_train, peru_y_train)\n",
        "predictions_rf = rf_exp.predict(peru_X_test)\n",
        "train_predictions_rf = rf_exp.predict(peru_X_train)\n",
        "mse_rf = mean_squared_error(peru_y_test, predictions_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "print(rmse_rf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExJG4QPztPPa"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzLn9anQytXJ"
      },
      "source": [
        "## XGboost\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-UtwfgjyupL"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance, plot_tree\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "plt.style.use('fivethirtyeight')\n",
        "reg = xgb.XGBRegressor(n_estimators=1000)\n",
        "reg.fit(peru_X_train, peru_y_train,\n",
        "        eval_set=[(peru_X_train, peru_y_train), (peru_X_test, peru_y_test)],\n",
        "        early_stopping_rounds=50,\n",
        "       verbose=False)\n",
        "preds = reg.predict(peru_X_test)\n",
        "rmse = np.sqrt(mean_squared_error(peru_y_test, preds))\n",
        "pred_train = reg.predict(peru_X_train)\n",
        "peru_y_train = np.array(peru_y_train).reshape((np.array(peru_y_train).shape[0],1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}